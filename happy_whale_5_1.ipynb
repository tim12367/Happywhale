{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0761e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "import heapq\n",
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2abcba0",
   "metadata": {},
   "source": [
    "# 讀入圖片路徑&處理label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 訓練資料夾路徑\n",
    "\n",
    "train_path = r\"E:\\hd_data_512_no_pad\"\n",
    "\n",
    "# 有多少資料夾 ( 分幾類 )\n",
    "\n",
    "img_classes = len(os.listdir(train_path))\n",
    "print(img_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db2998",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# img_path 圖片路徑, y 圖片分類ID \n",
    "\n",
    "img_path = []\n",
    "y = []\n",
    "\n",
    "# root 表示當前正在訪問的文件夾路徑\n",
    "# dirs 表示該文件夾下的 子目錄名list\n",
    "# files 表示該文件夾下的 文件list\n",
    "\n",
    "for root, dirs, files in os.walk(train_path):\n",
    "\n",
    "    # 遍歷文件\n",
    "\n",
    "    for f in files:\n",
    "        \n",
    "        # img_path 加入圖片路徑\n",
    "        \n",
    "        img_path.append(os.path.join(root, f))\n",
    "        \n",
    "        # y 加入ID\n",
    "        \n",
    "        y.append(root.split(\"\\\\\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7819c6a-690b-4d09-bf3c-8c2314b53fe3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 創建data前洗牌\n",
    "\n",
    "z = list(zip(img_path, y))\n",
    "random.shuffle(z)\n",
    "img_path, y = list(zip(*z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e3ab6-103c-46ae-9432-0b48f5645c0f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(img_path), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# label轉換成數字\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "labelencode_y = labelencoder.fit_transform(y)\n",
    "\n",
    "labelencode_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cbe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ID對數字的轉換字典\n",
    "\n",
    "id_to_num = dict(zip(y,labelencode_y))\n",
    "\n",
    "# 數字轉ID的轉換字典\n",
    "\n",
    "num_to_id = dict(zip(labelencode_y,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 數字轉onehot\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "onehotencode_y = onehotencoder.fit_transform(np.array(labelencode_y).reshape(-1,1)).toarray()\n",
    "\n",
    "onehotencode_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5fc338",
   "metadata": {},
   "source": [
    "# 批次處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b0f1cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 建立dataset\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "(\n",
    "    tf.cast(img_path,dtype=tf.string),\n",
    "    tf.cast(onehotencode_y,dtype=tf.uint8)\n",
    ")\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動分配訓練與預處理時間\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE \n",
    "\n",
    "# 路徑讀取圖片 前處理\n",
    "\n",
    "def decodeImg_label(img_path, label):\n",
    "    \n",
    "    # 讀取檔案\n",
    "    \n",
    "    raw = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(raw, channels=3)\n",
    "    image = tf.image.resize(image, (456, 456))\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_hue(image, 0.01)\n",
    "    image = tf.image.random_saturation(image, 0.70, 1.30)\n",
    "    image = tf.image.random_contrast(image, 0.80, 1.20)\n",
    "    image = tf.image.random_brightness(image, 0.10)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(decodeImg_label, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52830d-b380-42de-828d-46412a5c91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 預取\n",
    "\n",
    "dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808ef29-eb3d-4197-8594-1bded38739c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load舊模型\n",
    "\n",
    "# model = tf.keras.models.load_model(r\"D:\\DATA\\dolphin\\model\\20220501-1445(0.17557).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23768ab-16a0-4a50-a406-da46ca831b9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7ffbe-9bb9-4844-bde4-9ba16bae8138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 去掉前處理層\n",
    "\n",
    "model = Model(model.layers[2].input, model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897f2b0-db7f-4195-9962-fb7d1e57a196",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37765e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(r\"D:\\DATA\\dolphin\\test\\logdir\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"loss\",\n",
    "                                                  factor = 0.5,\n",
    "                                                  patience = 2,\n",
    "                                                  min_lr = 0)\n",
    "print(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fda9b7-651c-4d95-b435-c5c803060b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.categorical_crossentropy,\n",
    "        metrics=[tf.keras.metrics.TopKCategoricalAccuracy(),\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba81802",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# train model\n",
    "\n",
    "history = model.fit(dataset.shuffle(4096).batch(1),\n",
    "                    epochs=20,\n",
    "                    callbacks=[tensorboard_callback,tensorboard_callback,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec63bd-59d9-496e-9a78-f0117ce72e2c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model.layers[-47:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b434fbe3-b841-4ee3-87d0-d8b0c3ba8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 解凍模型\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    # We unfreeze the top 47 layers while leaving BatchNorm layers frozen\n",
    "    for layer in model.layers[-47:]:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=tf.keras.losses.categorical_crossentropy,\n",
    "        metrics=[tf.keras.metrics.TopKCategoricalAccuracy(),\"accuracy\"]\n",
    "    )\n",
    "\n",
    "\n",
    "unfreeze_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1047dce1-52a2-44a1-ad2e-d658dbbef840",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "history = model.fit(dataset.shuffle(4096).batch(8),\n",
    "                    epochs=10,\n",
    "                    callbacks=[tensorboard_callback,tensorboard_callback,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# 存檔\n",
    "\n",
    "now_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "model.save(f'D:\\\\DATA\\\\dolphin\\\\model\\\\{now_time}.h5')\n",
    "print(now_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1b5a6-df8a-4927-8206-50a21816d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 預測資料夾路徑\n",
    "\n",
    "test_path = r\"E:\\test_data_512\"\n",
    "\n",
    "# 所有圖片路徑\n",
    "\n",
    "test_img_name = os.listdir(test_path)\n",
    "test_img_path = list(map(lambda x : test_path + \"\\\\\" + x, test_img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd244b88-4e5f-4c53-b1ae-8d6d6e0b5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_img_name[:5],\"\\n\",test_img_path[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a76bef-dda9-4c9c-b557-5ec35120df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeImg(img_path):\n",
    "    \n",
    "    # 讀取檔案\n",
    "    \n",
    "    raw = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(raw, channels=3)\n",
    "    image = tf.image.resize(image, (456, 456))\n",
    "    image = tf.expand_dims(image, 0) # 增加一維\n",
    "    \"\"\"image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_hue(image, 0.01)\n",
    "    image = tf.image.random_saturation(image, 0.70, 1.30)\n",
    "    image = tf.image.random_contrast(image, 0.80, 1.20)\n",
    "    image = tf.image.random_brightness(image, 0.10)\"\"\"\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a3703-7d18-4fbd-a769-009c476cdc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立test_data\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "\n",
    "    (test_img_path,),\n",
    "\n",
    ")\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbe5ec-3af6-4edf-9af4-f63801b18122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_data 讀入圖片並前處理\n",
    "\n",
    "test_dataset = test_dataset.map(decodeImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a468e-1246-4980-a982-e261da405e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 開始預測\n",
    "\n",
    "predict_test_dataset = model.predict(test_dataset, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a91b1-666a-4ef4-935a-4150c285e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc49f3-0fd9-426d-83b6-ac1e597100fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_test_dataset.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cec4b8-ab87-4ccc-a830-21208e7be231",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_list = []\n",
    "for i in range(len(predict_test_dataset)):\n",
    "    prob_list.append(predict_test_dataset[i].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2b8e2d-8e48-4d7d-a837-de65ebc24565",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_list = np.array(prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbefff3-8dab-419e-872e-9e3347d6f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_prob = pd.Series(prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916113f4-c453-4edb-8a6e-42959fbd2791",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_prob.quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ca7c4-a9db-4993-97e6-6678e3f8f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_prob.quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8247ca-bacd-45b7-a95b-7aee49f0c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_prob.quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0b6f1-294d-4059-bd63-2cc8c4c9b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672158d-f052-4b08-b5e9-1c2921989470",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predict_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d777029-934f-48ba-8511-9aa729a2d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 寫入submission\n",
    "\n",
    "gate = p_prob.quantile(0.75)\n",
    "\n",
    "with open(f'D:\\\\DATA\\\\dolphin\\\\predict\\\\{now_time}.csv', 'w', newline='') as csvfile:\n",
    "    \n",
    "    # 建立 CSV 檔寫入器\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # 寫入標題\n",
    "    writer.writerow(['image', 'predictions'])\n",
    "\n",
    "    # 寫入資料\n",
    "    for i in range(len(predict_test_dataset)):\n",
    "        \n",
    "        # 轉成list\n",
    "        \n",
    "        m = predict_test_dataset[i].tolist()\n",
    "        max_number = heapq.nlargest(5, m) \n",
    "        max_index = []\n",
    "        for t in max_number:\n",
    "            index = m.index(t)\n",
    "            if index in max_index:\n",
    "                print(\"ERROR\")\n",
    "            max_index.append(index)\n",
    "            m[index] = 0\n",
    "        if predict_test_dataset[i].max() < gate:\n",
    "            predictions_str = \" \".join(list(map(lambda x: num_to_id[x], max_index[:4])))+\" new_individual\"\n",
    "        else:\n",
    "            predictions_str = \" \".join(list(map(lambda x: num_to_id[x], max_index)))\n",
    "\n",
    "        writer.writerow([test_img_name[i], predictions_str])\n",
    "print(f'D:\\\\DATA\\\\dolphin\\\\predict\\\\{now_time}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e0a894-fb44-4389-8cbd-214be2ba0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "i = random.randint(0,100)\n",
    "\n",
    "\n",
    "m = predict_test_dataset[i].tolist()\n",
    "max_number = heapq.nlargest(5, m) \n",
    "max_index = []\n",
    "for t in max_number:\n",
    "    index = m.index(t)\n",
    "    max_index.append(index)\n",
    "    m[index] = 0\n",
    "if predict_test_dataset[i].max() < 0.84:\n",
    "    predictions_str = \" \".join(list(map(lambda x: num_to_id[x], max_index[:4])))+\" new_individual\"\n",
    "else:\n",
    "    predictions_str = \" \".join(list(map(lambda x: num_to_id[x], max_index)))\n",
    "print(test_img[i])\n",
    "print(max_number)\n",
    "print(max_index)\n",
    "print(predictions_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d57a4f-7baf-45cf-9113-73f3d5a52b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
